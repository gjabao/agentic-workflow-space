# DOE Architecture Workspace

> **Directive-Orchestration-Execution Framework**
> Making unreliable LLM outputs work reliably in production.

## ğŸ¯ What is This?

A 3-layer architecture for building reliable AI-powered automation:

- **Layer 1: Directives** (`directives/*.md`) - WHAT to do (SOPs in markdown)
- **Layer 2: Orchestration** (AI Agent) - WHO decides (intelligent routing)
- **Layer 3: Execution** (`execution/*.py`) - HOW it's done (deterministic scripts)

## ğŸ“ Directory Structure

```
workspace/
â”œâ”€â”€ directives/           # SOPs (version controlled)
â”‚   â””â”€â”€ scrape_leads.md  # Example directive
â”œâ”€â”€ execution/            # Python tools (version controlled)
â”‚   â””â”€â”€ scrape_apify_leads.py # Lead scraping script
â”œâ”€â”€ .tmp/                 # Temporary files (NOT in git, regenerable)
â”‚   â”œâ”€â”€ dossiers/
â”‚   â”œâ”€â”€ scraped_data/
â”‚   â””â”€â”€ temp_exports/
â”œâ”€â”€ .env                  # Secrets (NOT in git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install Python dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy .env and add your API keys
# Edit .env and add:
# - APIFY_API_KEY
# - SSMASTERS_API_KEY
# - AZURE_OPENAI_API_KEY
```

### 3. Add Google Credentials (Required for Sheets Export)

To enable automatic Google Sheets export:

1.  **Create a Project** in [Google Cloud Console](https://console.cloud.google.com).
2.  **Enable APIs**: Search for and enable "Google Sheets API" and "Google Drive API".
3.  **Configure OAuth Consent Screen**:
    *   User Type: External
    *   App Name: "Lead Scraper"
    *   Add your email as a "Test User"
4.  **Create Credentials**:
    *   Go to Credentials > Create Credentials > OAuth client ID
    *   Application type: Desktop app
    *   Name: "Desktop Client"
5.  **Download JSON**:
    *   Download the JSON file
    *   Rename it to `credentials.json`
    *   Place it in the root directory: `Anti-Gravity Workspace/credentials.json`
6.  **First Run**: The script will open a browser window to authenticate. A `token.json` file will be created automatically.

### 4. Start Using

The AI agent will:
1. Read directives to understand what to do
2. Call appropriate execution scripts
3. Monitor progress and handle errors
4. Learn from failures (self-anneal)
5. Deliver results (typically as Google Sheets links)

## ğŸ“‹ How It Works

### Example: Scraping Leads

**User says:** "Scrape 100 dentists in New York"

**Agent does:**
```
1. Reads directives/scrape_leads.md âœ“
2. Finds execution/scrape_apify_leads.py âœ“
3. Validates inputs (industry, location, quantity) âœ“
4. Runs test scrape (25 leads) â†’ 88% valid â†’ PASS âœ“
5. Runs full scrape (100 leads) with progress updates âœ“
6. Validates output (92/100 valid emails) âœ“
7. Exports to Google Sheets âœ“
8. Returns: "âœ“ Complete! [Sheet link]"
```

**Total time:** ~3 minutes
**User active time:** 10 seconds

## ğŸ”§ Self-Annealing

When errors occur, the system:
1. **Detects** - Reads error messages carefully
2. **Analyzes** - Identifies root cause (code bug, API limit, etc.)
3. **Fixes** - Updates scripts with error handling, retries, validation
4. **Documents** - Updates directives with learnings
5. **Tests** - Verifies the fix works
6. **Result** - System is now stronger (won't fail the same way again)

## ğŸ“Š Quality Standards

- âœ… **Code**: Docstrings, error handling, type hints, logging
- âœ… **Output**: Data validation, deduplication, consistent formatting
- âœ… **Process**: Test before full run, progress updates, graceful error recovery

## ğŸ“ Key Principles

1. **Directives are sacred** - They preserve institutional knowledge
2. **Test small first** - 10-25 samples before full runs
3. **Cloud deliverables** - Results go to Google Sheets/Drive (shareable links)
4. **Local is temporary** - `.tmp/` files can be deleted anytime
5. **Ask, don't guess** - Clarify when uncertain

## ğŸ“– Documentation

See `Gemini.md` for complete agent instructions and architecture details.

## ğŸ¤ Contributing

When adding new capabilities:
1. Create directive in `directives/[name].md`
2. Create execution script in `execution/[name].py`
3. Test thoroughly with small samples
4. Document learnings and edge cases
5. Update this README if needed

---

**Remember:** This system learns from failures. Each error makes it stronger. ğŸš€
